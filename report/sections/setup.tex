\section{Setup}
\label{sec:setup}

\subsection{Hardware}
% TODO: Describe the robot we are designing for
% TODO: Describe the sensors available
% TODO: Describe that we assume the robot to have some sort of communication method

For this project, a differential drive robot equipped with a camera, LiDAR, odometry, and communication capabilities was chosen. LiDAR and odometry are utilized for localization via AMCL (as discussed later---{\color{red} DISCUSS THIS} in \cref{sub:localization}). The camera is used to detect the search object and a global communication channel is needed for the robots to share data. To optain realistic parameters and utilize pre-existing 3D models, URDF files, and robot parameters, the Turtlebot 4 \cite{tb4} was chosen as the target platform. However, it is important to note that the software developed in this project can be adapted to run on any robot that meets the specified sensor and communication requirements by adjusting the corresponding parameters in the source code.
% TODO: I think it has wifi/bluetooth builtin
The Turtlebot 4 has all the required hardware apart from a {\color{red} designated communication unit}. As this project focuses on simulation, the simulator will be responsible for passing messages between robots as they are sent. The software implementation is therefore {\color{red} communication method agnostic} as long as the messages the robots send are received by the other robots.

% TODO: Maybe mark the sensors on the robot
\begin{figure}[h]
    \begin{center}
        \includegraphics[width=0.55\textwidth]{figures/tb4.png}
    \end{center}
    \caption{Turtlebot 4}\label{fig:tb4}
\end{figure}



\section{Software Structure}
% TODO: Introduce debug soup

% TODO: Find a home for this figure
% TODO: Find a nice color scheme
% TODO: Refer to this figure in the text
\begin{figure}
    \begin{center}
        \includegraphics[width=0.95\textwidth]{figures/software-structure.pdf}
    \end{center}
    \caption{Software structure of the project. Black arrows indicate a library dependency and green arrows denote ROS 2 communication through topics. Square boxes are Rust crates while green circles are ROS 2 nodes. Notice that the core library \texttt{botbrain} is not part of the ROS 2 dependent code. It can therefore be used by the simple simulator without ROS 2.}\label{fig:}
\end{figure}


The software is divided into three main parts, the robot behavior implementation, a simple custom 2D
simulator, and a ROS 2 environment with 3D realistic simulations.

\subsection{Robot Behavior}
The robot behaviors are implemented in the \texttt{botbrain} library. \texttt{botbrain} defines the \texttt{Robot} interface
which is the only way for outside programs to interact with a robotâ€™s internal state (see \cref{fig:robot-interface}).

\begin{figure}[H]
    \begin{center}
        \begin{minted}[autogobble]{rust}
            pub trait Robot {
                fn set_id(&mut self, id: RobotId);            // Set the id of the robot
                fn set_map(&mut self, world: Map);            // Set the world map

                fn input_pose(&mut self, pose: RobotPose);    // Input the angle of the robot
                fn input_cam(&mut self, cam: CamData);        // Input data from the camera
                fn input_lidar(&mut self, lidar: LidarData);  // Input data from the lidar
                fn input_msgs(&mut self, msgs: Vec<Message>); // Input messages from other robots

                fn get_id(&self) -> &RobotId;                 // Get the id of the robot
                ...
            }
        \end{minted}
    \end{center}
    \caption{Methods of the \texttt{Robot} interface.}\label{fig:robot-interface}
\end{figure}

Interface methods prefixed with \texttt{set} are used to set up the internal state of the robot and should be called after creating a robot and before any other methods. The \texttt{input} prefix is used in functions which should be called as often as possible to update the world view of the robot. \texttt{get}-methods do not change the state of the robot and may be called at any time. Notice that there is no method which "runs" the robot to generate a control signal. This is because a \texttt{Robot} only represents the robot state, not the algorithm which uses that state to generate a control output. To generate a control output, the dynamic \texttt{Robot} must be passed to a behavior function. This function is then free to read and write to the robot state, to generate a control signal as well as a list of messages which should be sent to the other robots.

Separating the robot state from its behavior allows multiple behaviors for the same internal state, which is useful for comparing different algorithms.

\subsection{Using Rust}
% TODO: Describe how we integrated with colcon
The core logic of this project is implemented entirely in Rust. While this choice was primarily driven by preference, it presents both advantages and challenges that impact the overall system. ROS 2 does not officially support Rust, which can complicate integration with the ROS 2 ecosystem. To utilize ROS 2 from Rust, the \texttt{R2R} library \cite{r2r} was used. It provides bindings for the ROS Client Library (RCL) and generates code for ROS 2 message types. It functions effectively, although initial compilation times are longer compared to C++, as Rust bindings are generated during the build process. \\

A key advantage of using Rust is the enhanced robustness and correctness of the codebase. The Rust compiler guarantees no undefined behavior and enforces a strict type system where object lifetimes are verified at compile time. Consequently, the resulting code is less susceptible to errors and easier to refactor, especially in collaborative development environments.

\subsection{Two Simulators}
% TODO: Why two simulators?
% TODO: Shared behavior
% TODO: Performance differences
This project uses a simulator to simulator approach for validating robot behavior, as opposed to a simulator to real world comparison. The \texttt{simple\_sim} simulator provides a naive and simple environment useful for testing and validating robot behavior and was developed during this project. A Gazebo simulation is used to verify that the simple simulator is approximating the sensor inputs and motor commands in a realistic way that leads to similar results. The Gazebo simulation is always considered most correct. A major advantage of the simple simulator, is that it is very light weight and can run faster than real time with deterministic results. 
\Cref{fig:simulators} shows a screenshots of the simulators running the same world.

% TODO: Insert pictures of the depot in Simple Sim and Gazebo
\begin{figure}[h]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/simple_sim.png}
        \caption{Simple Simulator}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/gazebo_sim.png}
        \caption{Gazebo Simulator in ROS 2}
    \end{subfigure}
    \caption{Screenshots the simulators running the "depot" environment.}
      \label{fig:simulators}
\end{figure}
