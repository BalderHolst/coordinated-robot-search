\section{Results}
\label{sec:results}

This section presents a comparative evaluation of the developed search algorithms in terms of two key metrics: map coverage over time and computational expense. These metrics are analyzed across environments of varying difficulty. 
Additionally, the consistency between the two simulation environments—\texttt{simple\_sim} and the Gazebo ROS 2 setup—is evaluated to confirm the robustness and portability of the behavior implementations.
% TODO: Should we state a threshold for the consistency?
%


% TODO: Efficiency of the search algorithms
    % TODO: Different search algorithms
    % TODO: Different maps
    % TODO: Should be able to verify the parameters used

\subsection{Simulator Consistency}
A central goal of the dual-simulator framework is to ensure that algorithms implemented using the \texttt{botbrain} interface yield consistent behavior across both simulators. While Gazebo includes more realistic physics and non-deterministic behavior due to its time step and sensor noise, consistency in qualitative behavior (e.g., path shape, coverage trend) is still expected.
\subsubsection{Basic Movement}
To verify basic motion consistency, a simple circular movement behavior was executed in both simulators. As seen in \cref{fig:movement-simple-benchmark,fig:movement-ros2-benchmark}, the resulting paths are visually similar, confirming that the velocity commands generated by the behavior logic translate comparably across environments.
% Run with dumb:circle to compare
% TODO: New picture
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.95\textwidth]{./figures/consistency/simple-sim-paths-(after-10s)_rough_tune.png}
    \end{center}
    \caption{Path when running circular behavior in \texttt{simple\_sim}.}
    \label{fig:movement-simple-benchmark}
\end{figure}
% TODO: New picture
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.95\textwidth]{./figures/consistency/ros-2-paths-(after-10s)_rough_tune.png}
    \end{center}
    \caption{Path when running circular behavior in the ROS~2 Gazebo environment.}
    \label{fig:movement-ros2-benchmark}
\end{figure}

\subsubsection{Pathing}
A more complex evaluation was performed by comparing search behavior involving dynamic path planning. As shown in \cref{fig:coverage-benchmark}, the coverage curves produced by each simulator are closely aligned, particularly in early and mid-stage exploration. Minor deviations are attributed to non-determinism in Gazebo and slight differences in physics and sensor modeling.

% How similar are the two simulators?
\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.95\textwidth]{./figures/plots/gazebo_vs_simple_sim_pure_pathing.png}
    \end{center}
    \caption{Comparison of coverage over time between ROS~2 Gazebo and \texttt{simple\_sim} for identical pathing behavior.}
    \label{fig:coverage-benchmark}
\end{figure}

\subsection{Search Algorithm Benchmarks}
To evaluate search efficiency, each algorithm was executed across multiple randomly generated maps. The benchmark shown in \cref{fig:search-coverage-benchmark} presents average coverage over 10 runs, along with minimum and maximum bounds for each time step.

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.95\textwidth]{./figures/plots/benchmarks/coverage-over-10-runs.png}
    \end{center}
    \caption{Coverage performance of search algorithms over 10 runs starting in random positions in the same environment. Shaded regions represent the range between minimum and maximum coverage at each time step.}
    \label{fig:coverage-benchmark}
\end{figure}

All algorithms eventually achieve full coverage, though their exploration efficiency varies significantly. 
Gradient-based methods tend to cover local areas quickly but slow down due to diminishing gradients near fully explored zones. 
Frontier-based methods achieve higher global efficiency by directing robots toward unknown regions, but at a higher computational cost. The hybrid method strikes a balance by switching strategies based on local exploration progress. 
Deep reinforcement learning shows promise but requires further tuning for consistent early-stage performance.

\subsection{Computation Time}
% Use step_time in simple sim
% Compare algorithms on the same map:
    % CPU time
    % Memory usage
