\section{Related Work}
% TODO: How can autonomous robots be used 
% TODO: Refer to related work
%         - Nature
%         - AI
%         - Behavioral algorithms for grass cutting
%         - Search and rescue?
% TODO: Reflections (what is yet to be done?)

% The concept of multiple entities collaborating to achieve a common goal is well-established. Nature offers numerous examples, where diverse species of animals and plants have co-evolved to enhance mutual survival.
% Ants, despite possessing only rudimentary communication methods, represent one of the most successful animal species. They communicate and work together effectively using chemical signals.

% A paper review by Janardan Kumar Verma \& Virender Ranga outlines the current state MRS and provides a taxonomy for describing types of MRS and the problems and solutions related to them. This article mentions several approaches solving the task assignment problem. Notable approaches include market-based, dynamic programming, optimisation based, behavior based and deep reinforcement learning. Market based task assignment involves an auction where robots bid on a task and the highest bidding robot gets assigned the task which results in nearly optimal task assignment. Dynamic programming approaches seek to calculate the optimal task assignment given the location and capabilities of all robots in the system. This usually requires information about the entire MRS to be solved and can therefore only be used in centralized approaches.

% A whole other approach is deep reinforcement learning. Here, the MRS learns to reduce cost function and find the optimal policy for selecting tasks. Advantages include being adaptive to any environment at the cost of extensive training.

Multi-robot systems (MRS) are a well-researched area of robotics with many applications. MRS architectures are typically categorized as either centralized or distributed. Centralized approaches typically have a main server, responsible for allocating tasks and path planning, whereas distributed algorithms involve individual planning running on each robot. Notable approaches to MRS control include market-based \cite{trigui2014market}, dynamic programming \cite{kato2011dp}, optimization-based, behavior-based, and deep reinforcement learning \cite{huttenrauch2019deep-swarm}. Market-based task assignment involves an auction where robots bid on a task, and the highest bidding robot gets assigned the task, which can result in nearly optimal assignments. Dynamic programming approaches seek to calculate the optimal task assignment given the location and capabilities of all robots in the system. This usually requires global information about the MRS to compute optimal task assignments and can therefore only be used in centralized approaches or in distributed systems where the entire state of the system is shared, as discussed in Section 5.1 of \cite{multi-robot-search-moving-target}. Behavior-based approaches are usually inspired by nature and include ideas such as laying down virtual “pheromones” or other signals, which implicitly communicate tasks to other robots. One paper found that “a coordinated group effort is possible without use of direct communication or robot differentiation” \cite{kube2000cooperative-ants}. This results in a system that relies less on direct messaging and more on emergent behavior. \\

This thesis takes a somewhat similar approach by sharing a continuous stream of observations between robots. The collective observations are then used to update the internal search map in each robot, which influences the robot's movement. This type of implicit communication has the advantage that the search algorithm's time complexity is not dependent on the number of robots in the system, but may allow for a higher search efficiency, as found in Section 5.3 of \cite{multi-robot-search-moving-target}. In this thesis, four approaches were explored: a simple, computationally cheap, gradient-based algorithm; a frontier exploration algorithm using A* for pathing; a hybrid algorithm switching between the gradient and frontier algorithms; and a deep reinforcement learning-based algorithm. These types of algorithms may not find the optimal solution for exploring an area but are robust, resilient, and applicable to a wide range of scenarios.
