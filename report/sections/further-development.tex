\section{Further Development}
% TODO: How could the project be further developed?
% TODO: Maybe combine this section with real-world implementation?

While this project demonstrates a complete simulation-based framework for coordinated robotic search, several avenues exist for further development and real-world deployment.

\subsection{Real World Implementation}
While this project has not been deployed on a physical robot, the entire software stack has been developed with real-world implementation in mind. 
Both the simulation architecture and behavioral algorithms are designed to be modular, portable, and compatible with commonly available robotics hardware and middleware. 
This section outlines how the system could be transferred from simulation to real-world execution.

To transition from simulation to a physical system, several components must be tested and refined to ensure reliable performance under real-world conditions:
\begin{itemize}
  \item \textbf{Sensor calibration and frame alignment}: Accurate transformations between LiDAR, camera, and base frames are crucial for consistent sensor fusion and localization.
  \item \textbf{Robust object detection}: The current object detection relies on simple color-based segmentation, which may perform poorly in diverse lighting or background conditions. More robust methods, such as learned object detection or depth filtering, could be introduced.
  \item \textbf{Communication reliability}: Real-world wireless communication introduces latency, packet loss, and variable range. Testing robustness to communication failure and implementing fault-tolerant strategies (e.g., message queuing or data compression) would be essential.
  \item \textbf{Real-time performance}: The behavior logic and path planning components should be profiled on embedded hardware to ensure that they meet real-time constraints.
  \item \textbf{ROS 2 control integration}: In the current setup, differential drive control is handled by Gazebo plugins. For real hardware, transitioning to \texttt{ros2\_control} would allow for unified controller deployment in both simulated and physical environments.
\end{itemize}

Developing a small-scale multi-robot testbed using platforms such as TurtleBot 4 would be a natural next step. This would allow for physical validation of the distributed algorithms, hardware-in-the-loop testing, and identification of practical implementation bottlenecks.

\subsubsection{Hardware Requirements}
The project targets a differential drive robot equipped with:
\begin{itemize}
  \item A 2D LiDAR scanner.
  \item An RGB camera with a known field of view.
  \item Wheel odometry or IMU for dead reckoning.
  \item A communication module (e.g., Wi-Fi or Zigbee).
\end{itemize}

While the TurtleBot 4 is used in simulation, the system can be adapted to other platforms by updating sensor interfaces and adjusting configuration parameters.

\subsubsection{Using ROS 2}
The primary method for deploying the behavior algorithms is through a dedicated ROS 2 node included in the project. 
This node interfaces with the robotâ€™s onboard sensors and actuators using standard ROS 2 topics. 
Specifically, it requires subscribtion to the following input topics:

\begin{itemize}
  \item \texttt{/scan}: LiDAR data, used for obstacle detection and localization.
  \item \texttt{/camera/image}: Image stream from the onboard RGB camera, used for object detection.
  \item \texttt{/amcl\_pose}: Robot pose estimated via AMCL (Adaptive Monte Carlo Localization), providing global localization within a known map.
\end{itemize}

These topics are typically published by standard ROS 2 packages, such as \texttt{nav2}, and drivers for commonly used platforms like the TurtleBot 4. 
The behavior node publishes control commands to the \texttt{/cmd\_vel} topic, which specifies linear and angular velocities for the robot.

In simulation, the differential drive system is modeled within Gazebo using its built-in plugins. 
However, as Gazebo is not intended for real-world deployment, a separate controller is required for physical robots. 
A widely adopted solution is the \texttt{ros2\_control} framework \cite{ros2-control}, which offers a collection of hardware interface controllers, including one for differential drive systems.
This framework also includes a Gazebo plugin that allows the same controller to be used both in simulation and on real hardware, ensuring consistency across development and deployment environments.

\subsubsection{Using the Rust Library}
For platforms or embedded systems that do not support ROS 2, the behavior algorithms can be deployed using the standalone \texttt{botbrain} Rust library. 
This library exposes a high-level \texttt{Robot} interface which accepts sensor data and returns control commands and outgoing messages for communication.

% TODO: Maybe a simple code example??

This approach allows for flexible integration in environments where ROS 2 is not viable, such as microcontroller-based systems or custom embedded platforms.

\subsubsection{Communication Considerations}\label{sub:communication}
In simulation, message passing between robots is instantaneous and lossless. 
In a real-world implementation, communication can become a limiting factor. 
Several technologies could be considered:

\begin{itemize}
  \item \textbf{Wi-Fi}: High bandwidth, but may suffer from interference or limited range in large-scale outdoor applications.
  \item \textbf{Zigbee}: Low power and suitable for mesh networks but has limited bandwidth and range. Might not support high-frequency updates or large message payloads.
  \item \textbf{LoRa}: Long-range communication with minimal bandwidth. Only suitable for infrequent or compact messaging.
\end{itemize}

The system assumes one shared communication channel, where all robots broadcast their observations. 
Message serialization is already implemented in a compact binary format to reduce communication overhead. 
If communication becomes a bottleneck, strategies such as message prioritization or selective transmission (e.g., only sending certain changes) may be necessary.


\subsection{Advancing Deep Reinforcement Learning}
The reinforcement learning component could also be extended in multiple directions:
\begin{itemize}
  \item \textbf{Domain randomization}: To improve generalization to real-world conditions, domain randomization techniques could be employed during training (e.g., noise in sensors, and robot dynamics).
  \item \textbf{Curriculum learning}: Starting with simpler maps and gradually increasing complexity may improve convergence and performance.
  \item \textbf{Transfer learning}: Fine-tuning a trained policy in a physical environment could bridge the sim-to-real gap more efficiently than retraining from scratch.
  \item \textbf{Reward shaping}: More nuanced reward functions incorporating communication efficiency, time, and safety metrics could be explored to guide agent behavior more effectively.
\end{itemize}

Incorporating these techniques could help develop policies that are not only more effective but also more transferable and robust under real-world deployment conditions.

% TODO: Talk about NEAT or DQN with NEAT?
